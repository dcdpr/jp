when:
  path: "/v1beta/models/gemini-2.5-flash-lite:streamGenerateContent"
  method: POST
  query_param:
    - name: alt
      value: sse
  json_body_str: >-
    {
      "contents": [
        {
          "parts": [
            {
              "text": "Test message"
            }
          ],
          "role": "user"
        }
      ],
      "toolConfig": {
        "functionCallingConfig": {
          "mode": "NONE",
          "allowedFunctionNames": []
        }
      },
      "generationConfig": {
        "maxOutputTokens": 64000,
        "thinkingConfig": {
          "includeThoughts": true,
          "thinkingBudget": 12800,
          "thinkingLevel": null
        }
      }
    }
then:
  status: 200
  header:
    - name: content-type
      value: text/event-stream
  body: |+
    data: {"candidates": [{"content": {"parts": [{"text": "**Verifying Receipt of Message**\n\nI've received the \"Test message.\" My immediate priority is to respond in a friendly and confirming manner. I'm focusing on acknowledging its receipt, which will demonstrate functionality and show I'm responsive. I want to convey my understanding of the user's intent: testing for responsiveness or initiating a conversation.\n\n\n","thought": true}],"role": "model"},"index": 0}],"usageMetadata": {"promptTokenCount": 3,"totalTokenCount": 72,"promptTokensDetails": [{"modality": "TEXT","tokenCount": 3}],"thoughtsTokenCount": 69},"modelVersion": "gemini-2.5-flash-lite","responseId": "Wh1FaZGKE8LlxN8PmY7v2QU"}
    
    data: {"candidates": [{"content": {"parts": [{"text": "**Responding to the Inquiry**\n\nI have carefully processed the user's \"Test message\". My current approach is to craft a direct and positive response that emphasizes my readiness to assist. I've considered several reply options, and settled on a friendly confirmation. I'm prioritizing clarity and functionality in my initial interaction. The ultimate aim is to reassure the user and offer immediate support.\n\n\n","thought": true}],"role": "model"},"index": 0}],"usageMetadata": {"promptTokenCount": 3,"totalTokenCount": 264,"promptTokensDetails": [{"modality": "TEXT","tokenCount": 3}],"thoughtsTokenCount": 261},"modelVersion": "gemini-2.5-flash-lite","responseId": "Wh1FaZGKE8LlxN8PmY7v2QU"}
    
    data: {"candidates": [{"content": {"parts": [{"text": "Test message received! I'm here and ready. How can I help you today?"}],"role": "model"},"finishReason": "STOP","index": 0}],"usageMetadata": {"promptTokenCount": 3,"candidatesTokenCount": 16,"totalTokenCount": 280,"promptTokensDetails": [{"modality": "TEXT","tokenCount": 3}],"thoughtsTokenCount": 261},"modelVersion": "gemini-2.5-flash-lite","responseId": "Wh1FaZGKE8LlxN8PmY7v2QU"}
    
