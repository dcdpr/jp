when:
  path: "/v1beta/models/gemini-2.5-flash-lite:streamGenerateContent"
  method: POST
  query_param:
    - name: alt
      value: sse
  json_body_str: >-
    {
      "contents": [
        {
          "parts": [
            {
              "text": "Test message"
            }
          ],
          "role": "user"
        }
      ],
      "toolConfig": {
        "functionCallingConfig": {
          "mode": "NONE",
          "allowedFunctionNames": []
        }
      },
      "generationConfig": {
        "maxOutputTokens": 64000,
        "thinkingConfig": {
          "includeThoughts": true,
          "thinkingBudget": 12800,
          "thinkingLevel": null
        }
      }
    }
then:
  status: 200
  header:
    - name: content-type
      value: text/event-stream
  body: |-
    data: {"candidates": [{"content": {"parts": [{"text": "**Confirming System Readiness**\n\nI've processed the test message and interpreted it as a system check. My current strategy involves directly acknowledging the message as a test and confirming the system's readiness to proceed with more complex tasks. I plan to construct a response that is concise and clearly indicates that I'm active and listening.\n\n\n","thought": true}],"role": "model"},"index": 0}],"usageMetadata": {"promptTokenCount": 3,"totalTokenCount": 79,"promptTokensDetails": [{"modality": "TEXT","tokenCount": 3}],"thoughtsTokenCount": 76},"modelVersion": "gemini-2.5-flash-lite","responseId": "6xo4aeChIZ7W7M8PleWw4AE"}

    data: {"candidates": [{"content": {"parts": [{"text": "**Developing an Appropriate Response**\n\nI'm now refining the draft response, aiming for optimal conciseness and helpfulness. The objective is to convey both acknowledgment and proactive availability. I've considered several options, like a direct confirmation of reception and a proactive invitation to proceed, and I've settled on a concise, combined approach. The final touch involves ensuring a polite and welcoming tone.\n\n\n","thought": true}],"role": "model"},"index": 0}],"usageMetadata": {"promptTokenCount": 3,"totalTokenCount": 213,"promptTokensDetails": [{"modality": "TEXT","tokenCount": 3}],"thoughtsTokenCount": 210},"modelVersion": "gemini-2.5-flash-lite","responseId": "6xo4aeChIZ7W7M8PleWw4AE"}

    data: {"candidates": [{"content": {"parts": [{"text": "Test message received! I'm here and ready to help. What can I do for you?"}],"role": "model"},"finishReason": "STOP","index": 0}],"usageMetadata": {"promptTokenCount": 3,"candidatesTokenCount": 18,"totalTokenCount": 231,"promptTokensDetails": [{"modality": "TEXT","tokenCount": 3}],"thoughtsTokenCount": 210},"modelVersion": "gemini-2.5-flash-lite","responseId": "6xo4aeChIZ7W7M8PleWw4AE"}
