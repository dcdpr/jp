when:
  path: "/v1beta/models/gemini-2.5-flash-lite:streamGenerateContent"
  method: POST
  query_param:
    - name: alt
      value: sse
  json_body_str: >-
    {
      "contents": [
        {
          "parts": [
            {
              "text": "Test message"
            }
          ],
          "role": "user"
        }
      ],
      "toolConfig": {
        "functionCallingConfig": {
          "mode": "NONE",
          "allowedFunctionNames": []
        }
      },
      "generationConfig": {
        "maxOutputTokens": 64000,
        "thinkingConfig": {
          "includeThoughts": true,
          "thinkingBudget": 12800,
          "thinkingLevel": null
        }
      }
    }
then:
  status: 200
  header:
    - name: content-type
      value: text/event-stream
  body: |+
    data: {"candidates": [{"content": {"parts": [{"text": "**Recognizing Test Intent**\n\nI'm currently processing a simple \"Test message.\" My primary focus is to identify the user's intent, which appears to be a basic system check or exploratory query. I'm formulating a response that is both polite and helpful, acknowledging the test message effectively.\n\n\n","thought": true}],"role": "model"},"index": 0}],"usageMetadata": {"promptTokenCount": 3,"totalTokenCount": 73,"promptTokensDetails": [{"modality": "TEXT","tokenCount": 3}],"thoughtsTokenCount": 70},"modelVersion": "gemini-2.5-flash-lite","responseId": "Wh1Facf9Es-gxN8P0ubliAY"}
    
    data: {"candidates": [{"content": {"parts": [{"text": "**Crafting a Polite Response**\n\nI've refined my initial response, landing on \"Test message received! I'm here and ready to assist. What can I help you with today?\". I prioritized a balance of acknowledging the test, confirming functionality, and offering further assistance. My initial responses were too short, and others a bit too casual. This feels like a good fit for this scenario.\n\n\n","thought": true}],"role": "model"},"index": 0}],"usageMetadata": {"promptTokenCount": 3,"totalTokenCount": 313,"promptTokensDetails": [{"modality": "TEXT","tokenCount": 3}],"thoughtsTokenCount": 310},"modelVersion": "gemini-2.5-flash-lite","responseId": "Wh1Facf9Es-gxN8P0ubliAY"}
    
    data: {"candidates": [{"content": {"parts": [{"text": "Test message received! I'm here and ready to assist. What can I help you with today?"}],"role": "model"},"finishReason": "STOP","index": 0}],"usageMetadata": {"promptTokenCount": 3,"candidatesTokenCount": 19,"totalTokenCount": 332,"promptTokensDetails": [{"modality": "TEXT","tokenCount": 3}],"thoughtsTokenCount": 310},"modelVersion": "gemini-2.5-flash-lite","responseId": "Wh1Facf9Es-gxN8P0ubliAY"}
    
