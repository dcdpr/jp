when:
  path: "/v1beta/models/gemini-2.5-flash-lite:streamGenerateContent"
  method: POST
  query_param:
    - name: alt
      value: sse
  json_body_str: >-
    {
      "contents": [
        {
          "parts": [
            {
              "text": "Test message"
            }
          ],
          "role": "user"
        }
      ],
      "toolConfig": {
        "functionCallingConfig": {
          "mode": "NONE",
          "allowedFunctionNames": []
        }
      },
      "generationConfig": {
        "maxOutputTokens": 64000,
        "thinkingConfig": {
          "includeThoughts": true,
          "thinkingBudget": 12800,
          "thinkingLevel": null
        }
      }
    }
then:
  status: 200
  header:
    - name: content-type
      value: text/event-stream
  body: |+
    data: {"candidates": [{"content": {"parts": [{"text": "**Assessing the Interaction**\n\nI've identified the user's likely intent: to test the system's responsiveness. It's a simple input, so the goal is equally straightforward â€“ a helpful and appropriate response acknowledging the interaction. The core task is now in responding appropriately.\n\n\n","thought": true}],"role": "model"},"index": 0}],"usageMetadata": {"promptTokenCount": 3,"totalTokenCount": 75,"promptTokensDetails": [{"modality": "TEXT","tokenCount": 3}],"thoughtsTokenCount": 72},"modelVersion": "gemini-2.5-flash-lite","responseId": "oLaVafiCKu-0xN8P0rGNyQw"}
    
    data: {"candidates": [{"content": {"parts": [{"text": "**Refining the Response**\n\nI've determined the best response to the test message as \"Hello! I received your test message. How can I help you today?\". This balances acknowledgment with a prompt for further interaction. My next step is to prepare it for implementation, making it ready for a real-time interaction.\n\n\n","thought": true}],"role": "model"},"index": 0}],"usageMetadata": {"promptTokenCount": 3,"totalTokenCount": 322,"promptTokensDetails": [{"modality": "TEXT","tokenCount": 3}],"thoughtsTokenCount": 319},"modelVersion": "gemini-2.5-flash-lite","responseId": "oLaVafiCKu-0xN8P0rGNyQw"}
    
    data: {"candidates": [{"content": {"parts": [{"text": "Hello! I received your test message. How can I help you today?"}],"role": "model"},"finishReason": "STOP","index": 0}],"usageMetadata": {"promptTokenCount": 3,"candidatesTokenCount": 13,"totalTokenCount": 335,"promptTokensDetails": [{"modality": "TEXT","tokenCount": 3}],"thoughtsTokenCount": 319},"modelVersion": "gemini-2.5-flash-lite","responseId": "oLaVafiCKu-0xN8P0rGNyQw"}
    
