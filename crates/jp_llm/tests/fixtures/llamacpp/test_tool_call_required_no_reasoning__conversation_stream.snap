---
source: crates/jp_test/src/mock.rs
expression: v
---
[
  {
    "type": "config_delta",
    "timestamp": "2020-01-01 00:00:00.0",
    "delta": {
      "inherit": false,
      "config_load_paths": [],
      "extends": [],
      "assistant": {
        "tool_choice": "auto",
        "model": {
          "id": {
            "provider": "llamacpp",
            "name": "test"
          },
          "parameters": {
            "reasoning": "off",
            "stop_words": [],
            "other": {}
          }
        },
        "request": {
          "max_retries": 0,
          "base_backoff_ms": 0,
          "max_backoff_secs": 0
        }
      },
      "conversation": {
        "title": {
          "generate": {
            "auto": false
          }
        },
        "tools": {
          "*": {
            "run": "ask",
            "result": "unattended",
            "style": {
              "hidden": false,
              "inline_results": {
                "truncate": {
                  "lines": 10
                }
              },
              "results_file_link": "full",
              "parameters": "json"
            }
          }
        }
      },
      "style": {
        "code": {
          "theme": "",
          "color": false,
          "line_numbers": false,
          "file_link": "osc8",
          "copy_link": "osc8"
        },
        "markdown": {
          "wrap_width": 0,
          "table_max_column_width": 0,
          "hr_style": "line"
        },
        "reasoning": {
          "display": "full"
        },
        "streaming": {
          "progress": {
            "show": false,
            "delay_secs": 0,
            "interval_ms": 0
          }
        },
        "tool_call": {
          "show": false,
          "progress": {
            "show": false,
            "delay_secs": 0,
            "interval_ms": 0
          },
          "preparing": {
            "show": false,
            "delay_secs": 0,
            "interval_ms": 0
          }
        },
        "typewriter": {
          "text_delay": {
            "secs": 0,
            "nanos": 0
          },
          "code_delay": {
            "secs": 0,
            "nanos": 0
          }
        }
      },
      "editor": {
        "envs": []
      },
      "template": {
        "values": {}
      },
      "providers": {
        "llm": {
          "anthropic": {
            "api_key_env": "",
            "base_url": "",
            "chain_on_max_tokens": false,
            "beta_headers": []
          },
          "deepseek": {
            "api_key_env": "",
            "base_url": ""
          },
          "google": {
            "api_key_env": "",
            "base_url": ""
          },
          "llamacpp": {
            "base_url": ""
          },
          "ollama": {
            "base_url": ""
          },
          "openai": {
            "api_key_env": "",
            "base_url": "",
            "base_url_env": ""
          },
          "openrouter": {
            "api_key_env": "",
            "app_name": "",
            "base_url": ""
          }
        }
      }
    }
  },
  {
    "timestamp": "2020-01-01 00:00:00.0",
    "type": "chat_request",
    "content": "Please run the tool, providing whatever arguments you want."
  },
  {
    "timestamp": "2020-01-01 00:00:00.0",
    "type": "tool_call_request",
    "id": "kA4dduSivBJMGiJS5RMg4M0VXAbs5jiV",
    "name": "run_me",
    "arguments": {
      "foo": "YmFy",
      "bar": "Zm9v"
    }
  },
  {
    "timestamp": "2020-01-01 00:00:00.0",
    "type": "tool_call_response",
    "id": "kA4dduSivBJMGiJS5RMg4M0VXAbs5jiV",
    "content": "d29ya2luZyE=",
    "is_error": false
  },
  {
    "timestamp": "2020-01-01 00:00:00.0",
    "type": "chat_response",
    "reasoning": "Okay, the user asked me to run a tool with whatever arguments I want. I chose the \"run_me\" tool and provided \"foo\" as \"bar\" and \"bar\" as \"foo\". The response came back as \"working!\", which is a positive sign.\n\nNow, the user hasn't given a new query yet, but I need to be ready to respond. Since the previous interaction was about running a tool, maybe they want to know if the tool worked or what the next steps are. I should confirm that the tool executed successfully and perhaps ask if they need anything else. I should keep the tone friendly and helpful, making sure they know I'm here to assist further. Let me make sure my response is clear and concise."
  },
  {
    "timestamp": "2020-01-01 00:00:00.0",
    "type": "chat_response",
    "message": "The tool \"run_me\" executed successfully with the provided arguments! ðŸŽ‰ If you have any more tasks or need further assistance, feel free to ask. What's next?"
  }
]
