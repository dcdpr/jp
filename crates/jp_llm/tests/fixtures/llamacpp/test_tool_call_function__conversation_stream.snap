---
source: crates/jp_test/src/mock.rs
expression: v
---
[
  {
    "type": "config_delta",
    "timestamp": "2020-01-01 00:00:00.0",
    "delta": {
      "inherit": false,
      "config_load_paths": [],
      "extends": [],
      "assistant": {
        "tool_choice": "auto",
        "model": {
          "id": {
            "provider": "llamacpp",
            "name": "test"
          },
          "parameters": {
            "reasoning": "off",
            "stop_words": [],
            "other": {}
          }
        },
        "request": {
          "max_retries": 0,
          "base_backoff_ms": 0,
          "max_backoff_secs": 0
        }
      },
      "conversation": {
        "title": {
          "generate": {
            "auto": false
          }
        },
        "tools": {
          "*": {
            "run": "ask",
            "result": "unattended",
            "style": {
              "hidden": false,
              "inline_results": {
                "truncate": {
                  "lines": 10
                }
              },
              "results_file_link": "full",
              "parameters": "json"
            }
          }
        }
      },
      "style": {
        "code": {
          "theme": "",
          "color": false,
          "line_numbers": false,
          "file_link": "osc8",
          "copy_link": "osc8"
        },
        "markdown": {
          "wrap_width": 0,
          "table_max_column_width": 0,
          "hr_style": "line"
        },
        "reasoning": {
          "display": "full"
        },
        "streaming": {
          "progress": {
            "show": false,
            "delay_secs": 0,
            "interval_ms": 0
          }
        },
        "tool_call": {
          "show": false,
          "progress": {
            "show": false,
            "delay_secs": 0,
            "interval_ms": 0
          },
          "preparing": {
            "show": false,
            "delay_secs": 0,
            "interval_ms": 0
          }
        },
        "typewriter": {
          "text_delay": {
            "secs": 0,
            "nanos": 0
          },
          "code_delay": {
            "secs": 0,
            "nanos": 0
          }
        }
      },
      "editor": {
        "envs": []
      },
      "template": {
        "values": {}
      },
      "providers": {
        "llm": {
          "anthropic": {
            "api_key_env": "",
            "base_url": "",
            "chain_on_max_tokens": false,
            "beta_headers": []
          },
          "deepseek": {
            "api_key_env": "",
            "base_url": ""
          },
          "google": {
            "api_key_env": "",
            "base_url": ""
          },
          "llamacpp": {
            "base_url": ""
          },
          "ollama": {
            "base_url": ""
          },
          "openai": {
            "api_key_env": "",
            "base_url": "",
            "base_url_env": ""
          },
          "openrouter": {
            "api_key_env": "",
            "app_name": "",
            "base_url": ""
          }
        }
      }
    }
  },
  {
    "timestamp": "2020-01-01 00:00:00.0",
    "type": "chat_request",
    "content": "Please run the tool, providing whatever arguments you want."
  },
  {
    "timestamp": "2020-01-01 00:00:00.0",
    "type": "tool_call_request",
    "id": "Nx8MNLCopTT8Ka225frBpVRJmOxZe7Bb",
    "name": "run_me",
    "arguments": {
      "foo": "YmFy",
      "bar": "Zm9v"
    }
  },
  {
    "timestamp": "2020-01-01 00:00:00.0",
    "type": "tool_call_response",
    "id": "Nx8MNLCopTT8Ka225frBpVRJmOxZe7Bb",
    "content": "d29ya2luZyE=",
    "is_error": false
  },
  {
    "timestamp": "2020-01-01 00:00:00.0",
    "type": "chat_response",
    "reasoning": "Okay, the user asked me to run a tool with some arguments. I called the tool \"run_me\" and provided \"foo\" as \"bar\" and \"bar\" as \"foo\". The response was \"working!\", which is a positive sign. Now, the user hasn't given a specific question, just a statement. I need to figure out what they want next. Since they mentioned running the tool, maybe they want to see the output or have more interactions. The tool's response was \"working!\", so perhaps it's a test to check if the tool is functional. I should acknowledge that the tool ran successfully and offer further assistance. Maybe they want to test more commands or need help with something else. I'll respond by confirming the tool worked and ask how they'd like to proceed. Keeping it friendly and open-ended should cover their possible needs."
  },
  {
    "timestamp": "2020-01-01 00:00:00.0",
    "type": "chat_response",
    "message": "The tool \"run_me\" has been executed successfully with the provided arguments! ðŸŽ‰  \n\nIf you have any specific tasks or questions, feel free to ask, and I'll help you work through them. What would you like to do next?"
  }
]
